{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae1d236-5c7f-492c-976b-c5069e2dfa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard libraries\n",
    "import collections\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))  # Parent directory of 'soil_id'\n",
    "\n",
    "# Now import modules as a package\n",
    "from soil_id import config\n",
    "from soil_id.db import (\n",
    "    get_WISE30sec_data,\n",
    "    get_WRB_descriptions,\n",
    "    getSG_descriptions,\n",
    "    load_model_output,\n",
    "    save_model_output,\n",
    "    save_rank_output,\n",
    "    save_soilgrids_output,\n",
    ")\n",
    "from soil_id.services import (\n",
    "    get_soilgrids_classification_data,\n",
    "    get_soilgrids_property_data,\n",
    ")\n",
    "from soil_id.utils import (\n",
    "    agg_data_layer,\n",
    "    assign_max_distance_scores,\n",
    "    calculate_location_score,\n",
    "    compute_data_completeness,\n",
    "    drop_cokey_horz,\n",
    "    extract_values,\n",
    "    extract_WISE_data,\n",
    "    getCF_fromClass,\n",
    "    getClay,\n",
    "    getProfile,\n",
    "    getSand,\n",
    "    getTexture,\n",
    "    gower_distances,\n",
    "    pedon_color,\n",
    "    sg_get_and_agg,\n",
    "    silt_calc,\n",
    "    max_comp_depth,\n",
    "    convert_geometry_to_utm,\n",
    "    calculate_distances_and_intersections,\n",
    ")\n",
    "\n",
    "from soil_id.color import(\n",
    "    calculate_deltaE2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e82174a-108d-4493-9cc3-1243975c574e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef calculate_distances_and_intersections(mu_geo, point):\\n    \"\"\"\\n    Calculate distances and intersections of geometries to a point.\\n\\n    Args:\\n        mu_geo (GeoDataFrame): GeoDataFrame containing mapunit geometries.\\n        point (Point): Shapely Point object for the location of interest.\\n\\n    Returns:\\n        DataFrame: Contains mapunit keys, distances, and intersection flags.\\n    \"\"\"\\n\\n    # Ensure the point is wrapped in a GeoDataFrame and projected correctly\\n    point_utm, epsg_code = convert_geometry_to_utm(point)\\n    \\n    # Ensure the point is a GeoDataFrame (for compatibility)\\n    if not isinstance(point_utm, gpd.GeoDataFrame):\\n        point_utm = gpd.GeoDataFrame(geometry=[point_utm], crs=epsg_code)\\n    \\n    # Transform the GeoDataFrame to the same UTM CRS\\n    mu_geo_utm = mu_geo.to_crs(epsg_code)\\n    \\n    # Reset index for clean operations\\n    mu_geo_utm = mu_geo_utm.reset_index(drop=True)\\n    point_utm = point_utm.reset_index(drop=True)\\n    \\n    # Extract the single geometry for the point\\n    point_geometry = point_utm.geometry.iloc[0]\\n    \\n    # Calculate distances and intersections\\n    distances = mu_geo_utm[\"geometry\"].distance(point_geometry)\\n    intersects = mu_geo_utm[\"geometry\"].intersects(point_geometry)\\n    return pd.DataFrame(\\n        {\"MUGLB_NEW\": mu_geo_utm[\"MUGLB_NEW\"], \"dist_meters\": distances, \"pt_intersect\": intersects}\\n    )\\n\\n\\ndef convert_geometry_to_utm(geometry, src_crs=\"epsg:4326\", target_crs=None):\\n    \"\"\"\\n    Transforms a given geometry from its source coordinate reference system (CRS)\\n    to an appropriate Universal Transverse Mercator (UTM) CRS based on the geometry\\'s\\n    centroid location.\\n\\n    Parameters:\\n    - geometry (shapely.geometry.base.BaseGeometry): The geometry to transform, which\\n      could be any type of geometry, e.g., Point, Polygon.\\n    - src_crs (str, optional): The EPSG code of the source CRS of the geometry. Defaults\\n      to \\'epsg:4326\\'.\\n    - target_crs (str, optional): The EPSG code of the target CRS to which the geometry\\n      should be transformed. If None, the appropriate UTM CRS based on the geometry\\'s\\n      centroid will be calculated.\\n\\n    Returns:\\n    - tuple: A tuple containing the transformed geometry and the EPSG code of the\\n      target UTM CRS. The transformed geometry is in the new CRS, and distances from\\n      this geometry can be accurately calculated in linear units (meters).\\n\\n    Notes:\\n    - If the target_crs is not provided, the function calculates the correct UTM zone\\n      based on the longitude (from -180 to 180 degrees) and adjusts for the northern or\\n      southern hemisphere based on the latitude.\\n    - This function assumes the geometry is already in the specified source CRS and will\\n      convert it directly to the target CRS without additional CRS transformations.\\n    \"\"\"\\n    # If geometry is not a GeoDataFrame, wrap it into one\\n    if isinstance(geometry, Point):\\n        geometry = gpd.GeoDataFrame(geometry=[geometry], crs=src_crs)\\n    elif isinstance(geometry, gpd.GeoSeries):\\n        geometry = geometry.to_frame(name=\\'geometry\\')\\n\\n    # Project to source CRS (ensure proper handling)\\n    geometry = geometry.to_crs(src_crs)\\n\\n    # Calculate the centroid\\n    centroid = geometry.centroid.iloc[0]\\n    lon, lat = centroid.x, centroid.y\\n\\n    # Determine the UTM zone dynamically\\n    utm_zone = int((lon + 180) / 6) + 1\\n    hemisphere = \"north\" if lat >= 0 else \"south\"\\n    epsg_code = f\"326{utm_zone:02d}\" if hemisphere == \"north\" else f\"327{utm_zone:02d}\"\\n    target_crs = f\"EPSG:{epsg_code}\"\\n\\n    # Reproject geometry to the UTM CRS\\n    geometry_utm = geometry.to_crs(target_crs)\\n\\n    return geometry_utm, target_crs\\n\\n\\n\\ndef get_WISE30sec_data_csv(csv_file_path, MUGLB_NEW_Select):\\n    \"\"\"\\n    Retrieve WISE 30-second data from a CSV file based on selected MUGLB_NEW values.\\n\\n    Parameters:\\n    - csv_file_path (str): Path to the CSV file.\\n    - MUGLB_NEW_Select (list): List of MUGLB_NEW values to filter.\\n\\n    Returns:\\n    - pd.DataFrame: Filtered data.\\n    \"\"\"\\n    try:\\n        # Read the CSV file into a DataFrame\\n        data = pd.read_csv(csv_file_path)\\n        \\n        # Filter the DataFrame based on the MUGLB_NEW values\\n        filtered_data = data[data[\"MUGLB_NEW\"].isin(MUGLB_NEW_Select)]\\n        \\n        # Select specific columns\\n        selected_columns = [\\n            \"MUGLB_NEW\", \"COMPID\", \"id\", \"MU_GLOBAL\", \"NEWSUID\", \"SCID\", \"PROP\", \"CLAF\",\\n            \"PRID\", \"Layer\", \"TopDep\", \"BotDep\", \"CFRAG\", \"SDTO\", \"STPC\", \"CLPC\",\\n            \"CECS\", \"PHAQ\", \"ELCO\", \"SU_name\", \"FAO_SYS\"\\n        ]\\n        filtered_data = filtered_data[selected_columns]\\n        \\n        return filtered_data\\n\\n    except FileNotFoundError as e:\\n        logging.error(f\"File not found: {e}\")\\n        return None\\n    except Exception as err:\\n        logging.error(f\"An error occurred: {err}\")\\n        return None\\n\\n\\ndef get_WRB_descriptions_from_txt(WRB_Comp_List, txt_file_path):\\n    \"\"\"\\n    Retrieve WRB descriptions from a text file based on the provided WRB component list.\\n\\n    Parameters:\\n    - WRB_Comp_List (list): List of WRB components to filter.\\n    - txt_file_path (str): Path to the text file containing WRB descriptions.\\n\\n    Returns:\\n    - pd.DataFrame: Filtered DataFrame with WRB descriptions.\\n    \"\"\"\\n    try:\\n        # Load the text file using pandas\\n        data = pd.read_csv(txt_file_path, delimiter=\"\\t\")\\n        \\n        # Ensure the column names match the expected format\\n        required_columns = [\\n            \"WRB_tax\",\\n            \"WRB_tax_en\",\\n            \"Description_en\",\\n            \"Management_en\",\\n            \"WRB_tax_es\",\\n            \"Description_es\",\\n            \"Management_es\",\\n            \"WRB_tax_ks\",\\n            \"Description_ks\",\\n            \"Management_ks\",\\n            \"WRB_tax_fr\",\\n            \"Description_fr\",\\n            \"Management_fr\",\\n        ]\\n        if not all(col in data.columns for col in required_columns):\\n            raise ValueError(\"Text file is missing required columns.\")\\n        \\n        # Filter the data to include only rows with WRB_tax in WRB_Comp_List\\n        filtered_data = data[data[\"WRB_tax\"].isin(WRB_Comp_List)]\\n        \\n        return filtered_data\\n    except Exception as err:\\n        logging.error(f\"Error while retrieving WRB descriptions: {err}\")\\n        return None\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global\n",
    "# Standard libraries\n",
    "import logging\n",
    "import math\n",
    "import re\n",
    "\n",
    "# Third-party libraries\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from numpy.linalg import cholesky\n",
    "from osgeo import ogr\n",
    "from rosetta import SoilData, rosetta\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.sparse import issparse\n",
    "from scipy.stats import entropy, norm\n",
    "from shapely.geometry import Point, box\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.utils import validation\n",
    "\n",
    "'''\n",
    "def calculate_distances_and_intersections(mu_geo, point):\n",
    "    \"\"\"\n",
    "    Calculate distances and intersections of geometries to a point.\n",
    "\n",
    "    Args:\n",
    "        mu_geo (GeoDataFrame): GeoDataFrame containing mapunit geometries.\n",
    "        point (Point): Shapely Point object for the location of interest.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Contains mapunit keys, distances, and intersection flags.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the point is wrapped in a GeoDataFrame and projected correctly\n",
    "    point_utm, epsg_code = convert_geometry_to_utm(point)\n",
    "    \n",
    "    # Ensure the point is a GeoDataFrame (for compatibility)\n",
    "    if not isinstance(point_utm, gpd.GeoDataFrame):\n",
    "        point_utm = gpd.GeoDataFrame(geometry=[point_utm], crs=epsg_code)\n",
    "    \n",
    "    # Transform the GeoDataFrame to the same UTM CRS\n",
    "    mu_geo_utm = mu_geo.to_crs(epsg_code)\n",
    "    \n",
    "    # Reset index for clean operations\n",
    "    mu_geo_utm = mu_geo_utm.reset_index(drop=True)\n",
    "    point_utm = point_utm.reset_index(drop=True)\n",
    "    \n",
    "    # Extract the single geometry for the point\n",
    "    point_geometry = point_utm.geometry.iloc[0]\n",
    "    \n",
    "    # Calculate distances and intersections\n",
    "    distances = mu_geo_utm[\"geometry\"].distance(point_geometry)\n",
    "    intersects = mu_geo_utm[\"geometry\"].intersects(point_geometry)\n",
    "    return pd.DataFrame(\n",
    "        {\"MUGLB_NEW\": mu_geo_utm[\"MUGLB_NEW\"], \"dist_meters\": distances, \"pt_intersect\": intersects}\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_geometry_to_utm(geometry, src_crs=\"epsg:4326\", target_crs=None):\n",
    "    \"\"\"\n",
    "    Transforms a given geometry from its source coordinate reference system (CRS)\n",
    "    to an appropriate Universal Transverse Mercator (UTM) CRS based on the geometry's\n",
    "    centroid location.\n",
    "\n",
    "    Parameters:\n",
    "    - geometry (shapely.geometry.base.BaseGeometry): The geometry to transform, which\n",
    "      could be any type of geometry, e.g., Point, Polygon.\n",
    "    - src_crs (str, optional): The EPSG code of the source CRS of the geometry. Defaults\n",
    "      to 'epsg:4326'.\n",
    "    - target_crs (str, optional): The EPSG code of the target CRS to which the geometry\n",
    "      should be transformed. If None, the appropriate UTM CRS based on the geometry's\n",
    "      centroid will be calculated.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the transformed geometry and the EPSG code of the\n",
    "      target UTM CRS. The transformed geometry is in the new CRS, and distances from\n",
    "      this geometry can be accurately calculated in linear units (meters).\n",
    "\n",
    "    Notes:\n",
    "    - If the target_crs is not provided, the function calculates the correct UTM zone\n",
    "      based on the longitude (from -180 to 180 degrees) and adjusts for the northern or\n",
    "      southern hemisphere based on the latitude.\n",
    "    - This function assumes the geometry is already in the specified source CRS and will\n",
    "      convert it directly to the target CRS without additional CRS transformations.\n",
    "    \"\"\"\n",
    "    # If geometry is not a GeoDataFrame, wrap it into one\n",
    "    if isinstance(geometry, Point):\n",
    "        geometry = gpd.GeoDataFrame(geometry=[geometry], crs=src_crs)\n",
    "    elif isinstance(geometry, gpd.GeoSeries):\n",
    "        geometry = geometry.to_frame(name='geometry')\n",
    "\n",
    "    # Project to source CRS (ensure proper handling)\n",
    "    geometry = geometry.to_crs(src_crs)\n",
    "\n",
    "    # Calculate the centroid\n",
    "    centroid = geometry.centroid.iloc[0]\n",
    "    lon, lat = centroid.x, centroid.y\n",
    "\n",
    "    # Determine the UTM zone dynamically\n",
    "    utm_zone = int((lon + 180) / 6) + 1\n",
    "    hemisphere = \"north\" if lat >= 0 else \"south\"\n",
    "    epsg_code = f\"326{utm_zone:02d}\" if hemisphere == \"north\" else f\"327{utm_zone:02d}\"\n",
    "    target_crs = f\"EPSG:{epsg_code}\"\n",
    "\n",
    "    # Reproject geometry to the UTM CRS\n",
    "    geometry_utm = geometry.to_crs(target_crs)\n",
    "\n",
    "    return geometry_utm, target_crs\n",
    "\n",
    "\n",
    "\n",
    "def get_WISE30sec_data_csv(csv_file_path, MUGLB_NEW_Select):\n",
    "    \"\"\"\n",
    "    Retrieve WISE 30-second data from a CSV file based on selected MUGLB_NEW values.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file_path (str): Path to the CSV file.\n",
    "    - MUGLB_NEW_Select (list): List of MUGLB_NEW values to filter.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Filtered data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        data = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # Filter the DataFrame based on the MUGLB_NEW values\n",
    "        filtered_data = data[data[\"MUGLB_NEW\"].isin(MUGLB_NEW_Select)]\n",
    "        \n",
    "        # Select specific columns\n",
    "        selected_columns = [\n",
    "            \"MUGLB_NEW\", \"COMPID\", \"id\", \"MU_GLOBAL\", \"NEWSUID\", \"SCID\", \"PROP\", \"CLAF\",\n",
    "            \"PRID\", \"Layer\", \"TopDep\", \"BotDep\", \"CFRAG\", \"SDTO\", \"STPC\", \"CLPC\",\n",
    "            \"CECS\", \"PHAQ\", \"ELCO\", \"SU_name\", \"FAO_SYS\"\n",
    "        ]\n",
    "        filtered_data = filtered_data[selected_columns]\n",
    "        \n",
    "        return filtered_data\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"File not found: {e}\")\n",
    "        return None\n",
    "    except Exception as err:\n",
    "        logging.error(f\"An error occurred: {err}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_WRB_descriptions_from_txt(WRB_Comp_List, txt_file_path):\n",
    "    \"\"\"\n",
    "    Retrieve WRB descriptions from a text file based on the provided WRB component list.\n",
    "\n",
    "    Parameters:\n",
    "    - WRB_Comp_List (list): List of WRB components to filter.\n",
    "    - txt_file_path (str): Path to the text file containing WRB descriptions.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Filtered DataFrame with WRB descriptions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the text file using pandas\n",
    "        data = pd.read_csv(txt_file_path, delimiter=\"\\t\")\n",
    "        \n",
    "        # Ensure the column names match the expected format\n",
    "        required_columns = [\n",
    "            \"WRB_tax\",\n",
    "            \"WRB_tax_en\",\n",
    "            \"Description_en\",\n",
    "            \"Management_en\",\n",
    "            \"WRB_tax_es\",\n",
    "            \"Description_es\",\n",
    "            \"Management_es\",\n",
    "            \"WRB_tax_ks\",\n",
    "            \"Description_ks\",\n",
    "            \"Management_ks\",\n",
    "            \"WRB_tax_fr\",\n",
    "            \"Description_fr\",\n",
    "            \"Management_fr\",\n",
    "        ]\n",
    "        if not all(col in data.columns for col in required_columns):\n",
    "            raise ValueError(\"Text file is missing required columns.\")\n",
    "        \n",
    "        # Filter the data to include only rows with WRB_tax in WRB_Comp_List\n",
    "        filtered_data = data[data[\"WRB_tax\"].isin(WRB_Comp_List)]\n",
    "        \n",
    "        return filtered_data\n",
    "    except Exception as err:\n",
    "        logging.error(f\"Error while retrieving WRB descriptions: {err}\")\n",
    "        return None\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a68164d-20e1-4c7d-9a9c-3f0cc610d073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using UTM CRS: EPSG:32630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/jmaynard/Documents/GitHub/soil-id-algorithm/soil_id/utils.py:1404: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid = geometry.centroid.iloc[0]\n",
      "/mnt/c/Users/jmaynard/Documents/GitHub/soil-id-algorithm/soil_id/utils.py:84: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  mu_id_dist[\"distance\"] = mu_id_dist.groupby(\"MUGLB_NEW\")[\"dist_meters\"].transform(min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MUGLB_NEW  COMPID    id  MU_GLOBAL     NEWSUID  SCID  PROP CLAF   PRID  \\\n",
      "0        1530  108119  5549       1530  WD10001530     1    60  LXp  LXp/A   \n",
      "1        1530  108119  5550       1530  WD10001530     1    60  LXp  LXp/A   \n",
      "2        1530  108119  5551       1530  WD10001530     1    60  LXp  LXp/A   \n",
      "3        1530  108119  5552       1530  WD10001530     1    60  LXp  LXp/A   \n",
      "4        1530  108119  5553       1530  WD10001530     1    60  LXp  LXp/A   \n",
      "5        1530  108119  5554       1530  WD10001530     1    60  LXp  LXp/A   \n",
      "6        1530  108120  5555       1530  WD10001530     2    30  LVg  LVg/A   \n",
      "7        1530  108120  5556       1530  WD10001530     2    30  LVg  LVg/A   \n",
      "8        1530  108120  5557       1530  WD10001530     2    30  LVg  LVg/A   \n",
      "9        1530  108120  5558       1530  WD10001530     2    30  LVg  LVg/A   \n",
      "10       1530  108120  5559       1530  WD10001530     2    30  LVg  LVg/A   \n",
      "11       1530  108120  5560       1530  WD10001530     2    30  LVg  LVg/A   \n",
      "12       1530  108121  5561       1530  WD10001530     3    10  LPq  LPq/A   \n",
      "13       1453  107895  4676       1453  WD10001453     1    80  LXf  LXf/A   \n",
      "14       1453  107895  4677       1453  WD10001453     1    80  LXf  LXf/A   \n",
      "15       1453  107895  4678       1453  WD10001453     1    80  LXf  LXf/A   \n",
      "16       1453  107895  4679       1453  WD10001453     1    80  LXf  LXf/A   \n",
      "17       1453  107895  4680       1453  WD10001453     1    80  LXf  LXf/A   \n",
      "18       1453  107895  4681       1453  WD10001453     1    80  LXf  LXf/A   \n",
      "19       1453  107896  4682       1453  WD10001453     2    10  LPq  LPq/A   \n",
      "20       1453  107897  4683       1453  WD10001453     3    10  CMe  CMe/A   \n",
      "21       1453  107897  4684       1453  WD10001453     3    10  CMe  CMe/A   \n",
      "22       1453  107897  4685       1453  WD10001453     3    10  CMe  CMe/A   \n",
      "23       1453  107897  4686       1453  WD10001453     3    10  CMe  CMe/A   \n",
      "24       1453  107897  4687       1453  WD10001453     3    10  CMe  CMe/A   \n",
      "25       1453  107897  4688       1453  WD10001453     3    10  CMe  CMe/A   \n",
      "\n",
      "   Layer  ...  STPC  CLPC  CECS  PHAQ  ELCO            SU_name  FAO_SYS  \\\n",
      "0     D1  ...    22    14     5  6.20     0  Plinthic Lixisols    FAO90   \n",
      "1     D2  ...    21    19     4  5.90     0  Plinthic Lixisols    FAO90   \n",
      "2     D3  ...    20    26     5  5.80     0  Plinthic Lixisols    FAO90   \n",
      "3     D4  ...    20    28     6  5.80     0  Plinthic Lixisols    FAO90   \n",
      "4     D5  ...    22    28     6  5.80     0  Plinthic Lixisols    FAO90   \n",
      "5     D6  ...    23    28     6  5.80     0  Plinthic Lixisols    FAO90   \n",
      "6     D1  ...    22    16     9  6.30     1    Gleyic Luvisols    FAO90   \n",
      "7     D2  ...    20    23    11  6.30     1    Gleyic Luvisols    FAO90   \n",
      "8     D3  ...    18    33    14  6.50     1    Gleyic Luvisols    FAO90   \n",
      "9     D4  ...    19    35    15  6.70     2    Gleyic Luvisols    FAO90   \n",
      "10    D5  ...    21    36    16  6.90     2    Gleyic Luvisols    FAO90   \n",
      "11    D6  ...    22    36    16  7.00     3    Gleyic Luvisols    FAO90   \n",
      "12    D1  ...    29    20    16  6.70     1   Lithic Leptosols    FAO90   \n",
      "13    D1  ...    16    16     8  6.20     0    Ferric Lixisols    FAO90   \n",
      "14    D2  ...    15    23     6  6.10     0    Ferric Lixisols    FAO90   \n",
      "15    D3  ...    14    30     7  5.90     0    Ferric Lixisols    FAO90   \n",
      "16    D4  ...    14    35     7  5.80     0    Ferric Lixisols    FAO90   \n",
      "17    D5  ...    16    36     7  5.80     0    Ferric Lixisols    FAO90   \n",
      "18    D6  ...    17    36     7  5.80     0    Ferric Lixisols    FAO90   \n",
      "19    D1  ...    29    20    16  6.70     1   Lithic Leptosols    FAO90   \n",
      "20    D1  ...    31    29    22  6.40     2   Eutric Cambisols    FAO90   \n",
      "21    D2  ...    29    32    21  6.40     1   Eutric Cambisols    FAO90   \n",
      "22    D3  ...    29    33    22  6.50     1   Eutric Cambisols    FAO90   \n",
      "23    D4  ...    28    32    23  6.70     1   Eutric Cambisols    FAO90   \n",
      "24    D5  ...    28    31    23  6.90     1   Eutric Cambisols    FAO90   \n",
      "25    D6  ...    31    31    25  7.00     1   Eutric Cambisols    FAO90   \n",
      "\n",
      "     dist_meters  pt_intersect      distance  \n",
      "0   10697.101221         False  10697.101221  \n",
      "1   10697.101221         False  10697.101221  \n",
      "2   10697.101221         False  10697.101221  \n",
      "3   10697.101221         False  10697.101221  \n",
      "4   10697.101221         False  10697.101221  \n",
      "5   10697.101221         False  10697.101221  \n",
      "6   10697.101221         False  10697.101221  \n",
      "7   10697.101221         False  10697.101221  \n",
      "8   10697.101221         False  10697.101221  \n",
      "9   10697.101221         False  10697.101221  \n",
      "10  10697.101221         False  10697.101221  \n",
      "11  10697.101221         False  10697.101221  \n",
      "12  10697.101221         False  10697.101221  \n",
      "13      0.000000          True      0.000000  \n",
      "14      0.000000          True      0.000000  \n",
      "15      0.000000          True      0.000000  \n",
      "16      0.000000          True      0.000000  \n",
      "17      0.000000          True      0.000000  \n",
      "18      0.000000          True      0.000000  \n",
      "19      0.000000          True      0.000000  \n",
      "20      0.000000          True      0.000000  \n",
      "21      0.000000          True      0.000000  \n",
      "22      0.000000          True      0.000000  \n",
      "23      0.000000          True      0.000000  \n",
      "24      0.000000          True      0.000000  \n",
      "25      0.000000          True      0.000000  \n",
      "\n",
      "[26 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "wise_data = extract_WISE_data(lon = -1.57, lat=8.95, file_path = '/mnt/c/LandPKS_API_SoilID-master/global/wise30sec_poly_simp_soil.gpkg', buffer_dist=10000)\n",
    "print(wise_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33fd207d-0b5a-4512-afd7-973d4e2f9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "#                                 getSoilLocationBasedGlobal                                     #\n",
    "##################################################################################################\n",
    "def getSoilLocationBasedGlobal(lon, lat, plot_id):\n",
    "    # Extract HWSD-WISE Data\n",
    "    # Note: Need to convert HWSD shp to gpkg file\n",
    "    wise_data = extract_WISE_data(\n",
    "        lon,\n",
    "        lat,\n",
    "        # Temporarily change file path\n",
    "        file_path = '/mnt/c/LandPKS_API_SoilID-master/global/wise30sec_poly_simp_soil.gpkg',\n",
    "        #file_path=config.WISE_PATH,\n",
    "        #layer_name=None,\n",
    "        buffer_dist=10000,\n",
    "    )\n",
    "\n",
    "    # Component Data\n",
    "    mucompdata_pd = wise_data[[\"MUGLB_NEW\", \"SU_name\", \"distance\", \"PROP\", \"COMPID\", \"FAO_SYS\"]]\n",
    "    mucompdata_pd.columns = [\"mukey\", \"compname\", \"distance\", \"share\", \"cokey\", \"fss\"]\n",
    "    mucompdata_pd[\"distance\"] = pd.to_numeric(mucompdata_pd[\"distance\"])\n",
    "    mucompdata_pd[\"share\"] = pd.to_numeric(mucompdata_pd[\"share\"])\n",
    "    mucompdata_pd = mucompdata_pd.drop_duplicates().reset_index(drop=True)\n",
    " \n",
    "    ##############################################################################################\n",
    "    # Individual probability\n",
    "    # Based on Fan et al 2018 EQ 1, the conditional probability for each component is calculated\n",
    "    # by taking the sum of all occurances of a component in the home and adjacent mapunits and\n",
    "    # dividing this by the sum of all map units and components. We have modified this approach\n",
    "    # so that each instance of a component occurance is evaluated separately and assinged a\n",
    "    # weight and the max distance score for each component group is assigned to all component\n",
    "    # instances.\n",
    "    ##############################################################################################\n",
    "    ExpCoeff = -0.00036888  # Decays to 0.25 @ 10km\n",
    "    loc_scores = []\n",
    "    mucompdata_grouped = mucompdata_pd.groupby([\"mukey\", \"cokey\"], sort=False)\n",
    "\n",
    "    for (mukey, cokey), group in mucompdata_grouped:\n",
    "        loc_score = calculate_location_score(group, ExpCoeff)\n",
    "        loc_scores.append({\"cokey\": cokey, \"mukey\": mukey, \"distance_score\": round(loc_score, 3)})\n",
    "\n",
    "    loc_top_pd = pd.DataFrame(loc_scores)\n",
    "    loc_top_comp_prob = loc_top_pd.groupby(\"cokey\").distance_score.sum()\n",
    "    loc_bot_prob_sum = loc_top_pd.distance_score.sum()\n",
    "    cond_prob = (loc_top_comp_prob / loc_bot_prob_sum).reset_index(name=\"distance_score\")\n",
    "\n",
    "    mucompdata_pd = pd.merge(mucompdata_pd, cond_prob, on=\"cokey\", how=\"left\")\n",
    "    mucompdata_pd = mucompdata_pd.sort_values(\"distance_score\", ascending=False)\n",
    "    \n",
    "    mucompdata_pd = mucompdata_pd.reset_index(drop=True)\n",
    "    mucompdata_pd[\"distance\"] = mucompdata_pd[\"distance\"].round(4)\n",
    "    mucompdata_pd[\"Index\"] = mucompdata_pd.index\n",
    "\n",
    "    # Group by component name\n",
    "    mucompdata_grouped = mucompdata_pd.groupby(\"compname\", sort=False)\n",
    "\n",
    "    # Take at most 12 groups\n",
    "    mucompdata_comp_grps = [group for _, group in mucompdata_grouped][:12]\n",
    "\n",
    "    # Assign max distance scores to all members within each group\n",
    "    soilIDList_out = [assign_max_distance_scores(group) for group in mucompdata_comp_grps]\n",
    "\n",
    "    mucompdata_pd = pd.concat(soilIDList_out).reset_index(drop=True)\n",
    "    comp_key = mucompdata_pd[\"cokey\"].tolist()\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------------------\n",
    "    # Create horizon data table\n",
    "    columns_to_select = [\n",
    "        \"COMPID\",\n",
    "        \"TopDep\",\n",
    "        \"BotDep\",\n",
    "        \"id\",\n",
    "        \"Layer\",\n",
    "        \"SDTO\",\n",
    "        \"STPC\",\n",
    "        \"CLPC\",\n",
    "        \"CFRAG\",\n",
    "        \"CECS\",\n",
    "        \"PHAQ\",\n",
    "        \"ELCO\",\n",
    "        \"PROP\",\n",
    "        \"SU_name\",\n",
    "        \"FAO_SYS\",\n",
    "    ]\n",
    "    new_column_names = [\n",
    "        \"cokey\",\n",
    "        \"hzdept_r\",\n",
    "        \"hzdepb_r\",\n",
    "        \"chkey\",\n",
    "        \"hzname\",\n",
    "        \"sandtotal_r\",\n",
    "        \"silttotal_r\",\n",
    "        \"claytotal_r\",\n",
    "        \"total_frag_volume\",\n",
    "        \"CEC\",\n",
    "        \"pH\",\n",
    "        \"EC\",\n",
    "        \"comppct_r\",\n",
    "        \"compname\",\n",
    "        \"fss\",\n",
    "    ]\n",
    "\n",
    "    muhorzdata_pd = wise_data[columns_to_select]\n",
    "    muhorzdata_pd.columns = new_column_names\n",
    "    muhorzdata_pd = muhorzdata_pd[muhorzdata_pd[\"cokey\"].isin(comp_key)]\n",
    "    muhorzdata_pd[[\"hzdept_r\", \"hzdepb_r\"]] = (\n",
    "        muhorzdata_pd[[\"hzdept_r\", \"hzdepb_r\"]].fillna(0).astype(int)\n",
    "    )\n",
    "    muhorzdata_pd[\"texture\"] = muhorzdata_pd.apply(getTexture, axis=1)\n",
    "    muhorzdata_pd[\"texture\"] = muhorzdata_pd[\"texture\"].apply(\n",
    "        lambda x: str(x) if isinstance(x, np.ndarray) else x\n",
    "    )\n",
    "\n",
    "    # Rank components and sort by rank and depth\n",
    "    cokey_Index = {key: rank for rank, key in enumerate(comp_key)}\n",
    "    muhorzdata_pd[\"Comp_Rank\"] = muhorzdata_pd[\"cokey\"].map(cokey_Index)\n",
    "    muhorzdata_pd.sort_values([\"Comp_Rank\", \"hzdept_r\"], inplace=True)\n",
    "    muhorzdata_pd.drop(columns=\"Comp_Rank\", inplace=True)\n",
    "    muhorzdata_pd = muhorzdata_pd.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Check for duplicate component instances\n",
    "    hz_drop = drop_cokey_horz(muhorzdata_pd)\n",
    "    if hz_drop is not None:\n",
    "        muhorzdata_pd = muhorzdata_pd[~muhorzdata_pd.cokey.isin(hz_drop)]\n",
    "\n",
    "    # Update comp_key\n",
    "    comp_key = muhorzdata_pd[\"cokey\"].unique().tolist()\n",
    "\n",
    "    # Subset mucompdata_pd by new compname_key and add suffix to name if there are duplicates\n",
    "    mucompdata_pd = mucompdata_pd.loc[mucompdata_pd['cokey'].isin(comp_key)].reset_index(drop=True)\n",
    "    mucompdata_pd[\"compname_grp\"] = mucompdata_pd[\"compname\"]\n",
    "    \n",
    "    # Sort by 'distance_score' (descending) and 'distance' (ascending), then reset the index\n",
    "    mucompdata_pd = mucompdata_pd.sort_values(['distance_score', 'distance'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    # Add suffix to duplicate names\n",
    "    name_counts = collections.Counter(mucompdata_pd[\"compname\"])\n",
    "    for name, count in name_counts.items():\n",
    "        if count > 1:\n",
    "            for suffix in range(1, count + 1):\n",
    "                mucompdata_pd.loc[mucompdata_pd[\"compname\"] == name, \"compname\"] = name + str(\n",
    "                    suffix\n",
    "                )\n",
    "\n",
    "    # Add modified compname to muhorzdata\n",
    "    muhorzdata_name = muhorzdata_pd[[\"cokey\"]].merge(\n",
    "        mucompdata_pd[[\"cokey\", \"compname\"]], on=\"cokey\"\n",
    "    )\n",
    "    muhorzdata_pd[\"compname\"] = muhorzdata_name[\"compname\"]\n",
    "\n",
    "    # Group data by cokey for texture\n",
    "    muhorzdata_group_cokey = list(muhorzdata_pd.groupby(\"cokey\", sort=False))\n",
    "\n",
    "    # Initialize lists for storing data\n",
    "    getProfile_cokey = []\n",
    "    c_bottom_depths = []\n",
    "    clay_texture = []\n",
    "    snd_lyrs = []\n",
    "    cly_lyrs = []\n",
    "    txt_lyrs = []\n",
    "    hz_lyrs = []\n",
    "    rf_lyrs = []\n",
    "    cec_lyrs = []\n",
    "    ph_lyrs = []\n",
    "    ec_lyrs = []\n",
    "\n",
    "    for group_key, group in muhorzdata_group_cokey:\n",
    "        profile = (\n",
    "            group.sort_values(by=\"hzdept_r\")\n",
    "            .drop_duplicates(keep=\"first\")\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        c_very_bottom = max_comp_depth(profile)\n",
    "\n",
    "        sand_pct_intpl = getProfile(profile, \"sandtotal_r\")\n",
    "        sand_pct_intpl.columns = [\"c_sandpct_intpl\", \"c_sandpct_intpl_grp\"]\n",
    "        clay_pct_intpl = getProfile(profile, \"claytotal_r\")\n",
    "        clay_pct_intpl.columns = [\"c_claypct_intpl\", \"c_claypct_intpl_grp\"]\n",
    "        cf_pct_intpl = getProfile(profile, \"total_frag_volume\")\n",
    "        cf_pct_intpl.columns = [\"c_cfpct_intpl\", \"c_cfpct_intpl_grp\"]\n",
    "        cec_intpl = getProfile(profile, \"CEC\")\n",
    "        cec_intpl.columns = [\"c_cec_intpl\"]\n",
    "        ph_intpl = getProfile(profile, \"pH\")\n",
    "        ph_intpl.columns = [\"c_ph_intpl\"]\n",
    "        ec_intpl = getProfile(profile, \"EC\")\n",
    "        ec_intpl.columns = [\"c_ec_intpl\"]\n",
    "\n",
    "        combined_data = pd.concat(\n",
    "            [\n",
    "                sand_pct_intpl[[\"c_sandpct_intpl_grp\"]],  # DataFrame\n",
    "                clay_pct_intpl[[\"c_claypct_intpl_grp\"]],  # DataFrame\n",
    "                cf_pct_intpl[[\"c_cfpct_intpl_grp\"]],     # DataFrame\n",
    "                pd.DataFrame(profile.compname.unique(), columns=[\"compname\"]),  # Convert to DataFrame\n",
    "                pd.DataFrame(profile.cokey.unique(), columns=[\"cokey\"]),        # Convert to DataFrame\n",
    "                pd.DataFrame(profile.comppct_r.unique(), columns=[\"comppct\"]),  # Convert to DataFrame\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        combined_data.columns = [\n",
    "            \"sandpct_intpl\",\n",
    "            \"claypct_intpl\",\n",
    "            \"rfv_intpl\",\n",
    "            \"compname\",\n",
    "            \"cokey\",\n",
    "            \"comppct\",\n",
    "        ]\n",
    "\n",
    "        c_bottom_temp = pd.DataFrame(\n",
    "            {\n",
    "                \"cokey\": [combined_data[\"cokey\"].iloc[0]],\n",
    "                \"compname\": [combined_data[\"compname\"].iloc[0]],\n",
    "                \"c_very_bottom\": [int(c_very_bottom)],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        snd_d, hz_depb = agg_data_layer(sand_pct_intpl.c_sandpct_intpl, bottom=c_bottom_temp[\"c_very_bottom\"].iloc[0], depth=True)\n",
    "        cly_d = agg_data_layer(clay_pct_intpl.c_claypct_intpl, bottom=c_bottom_temp[\"c_very_bottom\"].iloc[0], depth=False)\n",
    "        txt_d = [\n",
    "            getTexture(row=None, sand=s, silt=(100 - (s + c)), clay=c) for s, c in zip(snd_d, cly_d)\n",
    "        ]\n",
    "        txt_d = pd.Series(txt_d, index=snd_d.index)\n",
    "\n",
    "        rf_d = agg_data_layer(cf_pct_intpl.c_cfpct_intpl, bottom=c_bottom_temp[\"c_very_bottom\"].iloc[0], depth=False)\n",
    "        cec_d = agg_data_layer(cec_intpl.c_cec_intpl, bottom=c_bottom_temp[\"c_very_bottom\"].iloc[0], depth=False)\n",
    "        ph_d = agg_data_layer(ph_intpl.c_ph_intpl, bottom=c_bottom_temp[\"c_very_bottom\"].iloc[0], depth=False)\n",
    "        ec_d = agg_data_layer(ec_intpl.c_ec_intpl, bottom=c_bottom_temp[\"c_very_bottom\"].iloc[0], depth=False)\n",
    "\n",
    "        # Fill NaN values and append to lists\n",
    "        for data_list, data in zip(\n",
    "            [snd_lyrs, cly_lyrs, txt_lyrs, rf_lyrs, cec_lyrs, ph_lyrs, ec_lyrs, hz_lyrs],\n",
    "            [snd_d, cly_d, txt_d, rf_d, cec_d, ph_d, ec_d, hz_depb],\n",
    "        ):\n",
    "            data_list.append(dict(data.fillna(\"\")))\n",
    "\n",
    "        c_bottom_depths.append(c_bottom_temp)\n",
    "        getProfile_cokey.append(combined_data)\n",
    "\n",
    "        comp_texture_list = [x for x in profile.texture.str.lower() if x]\n",
    "        clay_val = \"Yes\" if any(\"clay\" in string for string in comp_texture_list) else \"No\"\n",
    "        clay_texture_temp = pd.DataFrame(\n",
    "            {\"compname\": [combined_data[\"compname\"].iloc[0]], \"clay\": [clay_val]}\n",
    "        )\n",
    "        clay_texture.append(clay_texture_temp)\n",
    "\n",
    "    # Concatenate lists to form DataFrames\n",
    "    c_bottom_depths = pd.concat(c_bottom_depths, axis=0)\n",
    "    clay_texture = pd.concat(clay_texture, axis=0)\n",
    "    \n",
    "    # Subset mucompdata and muhorzdata DataFrames\n",
    "    mucompdata_pd = mucompdata_pd[mucompdata_pd[\"cokey\"].isin(c_bottom_depths.cokey)]\n",
    "    muhorzdata_pd = muhorzdata_pd[muhorzdata_pd[\"cokey\"].isin(c_bottom_depths.cokey)]\n",
    "\n",
    "    # Merge c_bottom_depth and clay_texture with mucompdata\n",
    "    mucompdata_pd = pd.merge(\n",
    "        mucompdata_pd, c_bottom_depths[[\"compname\", \"c_very_bottom\"]], on=\"compname\", how=\"left\"\n",
    "    )\n",
    "    mucompdata_pd = pd.merge(mucompdata_pd, clay_texture, on=\"compname\", how=\"left\")\n",
    "\n",
    "    # Create index for component instance display\n",
    "    mucompdata_comp_grps_list = []\n",
    "    mucompdata_comp_grps = [group for _, group in mucompdata_pd.groupby(\"compname_grp\", sort=False)]\n",
    "\n",
    "    for group in mucompdata_comp_grps:\n",
    "        group = group.sort_values(\"distance\").reset_index(drop=True)\n",
    "        soilID_rank = [True if idx == 0 else False for idx in range(len(group))]\n",
    "\n",
    "        group[\"soilID_rank\"] = soilID_rank\n",
    "        group[\"min_dist\"] = group.distance.iloc[0]\n",
    "\n",
    "        mucompdata_comp_grps_list.append(group)\n",
    "\n",
    "    mucompdata_pd = pd.concat(mucompdata_comp_grps_list).reset_index(drop=True)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------------------------------------\n",
    "    # SoilIDList output\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Format output data\n",
    "    soilIDRank_output = [\n",
    "        group[[\"compname\", \"sandpct_intpl\", \"claypct_intpl\", \"rfv_intpl\"]]\n",
    "        for group in getProfile_cokey\n",
    "    ]\n",
    "    soilIDRank_output_pd = pd.concat(soilIDRank_output, axis=0).reset_index(drop=True)\n",
    "\n",
    "    mucompdata_cond_prob = mucompdata_pd.sort_values(\n",
    "        \"distance_score\", ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Determine rank location\n",
    "    rank_id = 1\n",
    "    Rank_Loc = []\n",
    "    for rank in mucompdata_cond_prob[\"soilID_rank\"]:\n",
    "        Rank_Loc.append(str(rank_id) if rank else \"Not Displayed\")\n",
    "        rank_id += rank  # Increase rank_id only if rank is True\n",
    "    mucompdata_cond_prob[\"Rank_Loc\"] = Rank_Loc\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------------------------------------\n",
    "    # API output: Code outputs HWSD data without any alteration (i.e., texture class averaging)\n",
    "\n",
    "    # Handle NaN values\n",
    "    mucompdata_cond_prob.replace([np.nan, \"nan\", \"None\", [None]], \"\", inplace=True)\n",
    "\n",
    "    # Sort mucompdata_cond_prob by soilID_rank and distance_score\n",
    "    mucompdata_cond_prob = mucompdata_cond_prob.sort_values(\n",
    "        [\"soilID_rank\", \"distance_score\"], ascending=[False, False]\n",
    "    )\n",
    "    mucomp_index = mucompdata_cond_prob.index\n",
    "    \n",
    "    # Extract lists for constructing ID dictionary\n",
    "    siteName = mucompdata_cond_prob[\"compname\"].apply(lambda x: x.capitalize()).tolist()\n",
    "    compName = mucompdata_cond_prob[\"compname_grp\"].apply(lambda x: x.capitalize()).tolist()\n",
    "    score = mucompdata_cond_prob[\"distance_score\"].round(3).tolist()\n",
    "    rank_loc = mucompdata_cond_prob[\"Rank_Loc\"].tolist()\n",
    "    model_version = 3\n",
    "\n",
    "    # Step 3: Construct ID list directly from the sorted and cleaned DataFrame\n",
    "    ID = []\n",
    "    for i, idx in enumerate(mucompdata_cond_prob.index):\n",
    "        idT = {\n",
    "            \"name\": siteName[i],\n",
    "            \"component\": compName[i],\n",
    "            \"score_loc\": score[i],\n",
    "            \"rank_loc\": rank_loc[i],\n",
    "        }\n",
    "        ID.append(idT)\n",
    "\n",
    "    # Merge component descriptions\n",
    "    WRB_Comp_Desc = get_WRB_descriptions(\n",
    "        mucompdata_cond_prob[\"compname_grp\"].drop_duplicates().tolist()\n",
    "    )\n",
    "\n",
    "    mucompdata_cond_prob = pd.merge(\n",
    "        mucompdata_cond_prob, WRB_Comp_Desc, left_on=\"compname_grp\", right_on=\"WRB_tax\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Extract site information\n",
    "    Site = [\n",
    "        {\n",
    "            \"siteData\": {\n",
    "                \"mapunitID\": row.mukey,\n",
    "                \"componentID\": row.cokey,\n",
    "                \"fao\": row.fss,\n",
    "                \"share\": row.share,\n",
    "                \"distance\": round(row.distance, 3),\n",
    "                \"minCompDistance\": row.min_dist,\n",
    "                \"soilDepth\": row.c_very_bottom,\n",
    "            },\n",
    "            \"siteDescription\": {\n",
    "                key: row[key]\n",
    "                for key in [\n",
    "                    \"Description_en\",\n",
    "                    \"Management_en\",\n",
    "                    \"Description_es\",\n",
    "                    \"Management_es\",\n",
    "                    \"Description_ks\",\n",
    "                    \"Management_ks\",\n",
    "                    \"Description_fr\",\n",
    "                    \"Management_fr\",\n",
    "                ]\n",
    "            },\n",
    "        }\n",
    "        for _, row in mucompdata_cond_prob.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Reorder lists based on mucomp_index\n",
    "    hz_lyrs = [hz_lyrs[i] for i in mucomp_index]\n",
    "    snd_lyrs = [snd_lyrs[i] for i in mucomp_index]\n",
    "    cly_lyrs = [cly_lyrs[i] for i in mucomp_index]\n",
    "    txt_lyrs = [txt_lyrs[i] for i in mucomp_index]\n",
    "    rf_lyrs = [rf_lyrs[i] for i in mucomp_index]\n",
    "    cec_lyrs = [cec_lyrs[i] for i in mucomp_index]\n",
    "    ph_lyrs = [ph_lyrs[i] for i in mucomp_index]\n",
    "    ec_lyrs = [ec_lyrs[i] for i in mucomp_index]\n",
    "\n",
    "    output_SoilList = [\n",
    "        dict(\n",
    "            zip(\n",
    "                [\n",
    "                    \"id\",\n",
    "                    \"site\",\n",
    "                    \"bottom_depth\",\n",
    "                    \"sand\",\n",
    "                    \"clay\",\n",
    "                    \"texture\",\n",
    "                    \"rock_fragments\",\n",
    "                    \"cec\",\n",
    "                    \"ph\",\n",
    "                    \"ec\",\n",
    "                ],\n",
    "                item,\n",
    "            )\n",
    "        )\n",
    "        for item in zip(\n",
    "            ID, Site, hz_lyrs, snd_lyrs, cly_lyrs, txt_lyrs, rf_lyrs, cec_lyrs, ph_lyrs, ec_lyrs\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    def convert_to_serializable(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_to_serializable(v) for v in obj]\n",
    "        elif isinstance(obj, np.integer):  # Convert NumPy integers to Python int\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):  # Convert NumPy floats to Python float\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):  # Convert NumPy arrays to lists\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return obj\n",
    "        \n",
    "    output_SoilList_cleaned = convert_to_serializable(output_SoilList)\n",
    "\n",
    "    # Save data\n",
    "    if plot_id is None:\n",
    "        soilIDRank_output_pd.to_csv(config.SOIL_ID_RANK_PATH, index=None, header=True)\n",
    "        mucompdata_cond_prob.to_csv(config.SOIL_ID_PROB_PATH, index=None, header=True)\n",
    "    else:\n",
    "        save_model_output(\n",
    "            plot_id,\n",
    "            model_version,\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"metadata\": {\n",
    "                        \"location\": \"global\",\n",
    "                        \"model\": \"v2\",\n",
    "                        \"unit_measure\": {\n",
    "                            \"distance\": \"m\",\n",
    "                            \"depth\": \"cm\",\n",
    "                            \"cec\": \"cmol(c)/kg\",\n",
    "                            \"clay\": \"%\",\n",
    "                            \"rock_fragments\": \"cm3/100cm3\",\n",
    "                            \"sand\": \"%\",\n",
    "                            \"ec\": \"ds/m\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"soilList\": output_SoilList_cleaned,\n",
    "                }\n",
    "            ),\n",
    "            soilIDRank_output_pd.to_csv(index=None, header=True),\n",
    "            mucompdata_cond_prob.to_csv(index=None, header=True),\n",
    "        )\n",
    "\n",
    "    # Return the JSON output\n",
    "    return {\n",
    "        \"metadata\": {\n",
    "            \"location\": \"global\",\n",
    "            \"model\": \"v2\",\n",
    "            \"unit_measure\": {\n",
    "                \"distance\": \"m\",\n",
    "                \"depth\": \"cm\",\n",
    "                \"cec\": \"cmol(c)/kg\",\n",
    "                \"clay\": \"%\",\n",
    "                \"rock_fragments\": \"cm3/100cm3\",\n",
    "                \"sand\": \"%\",\n",
    "                \"ec\": \"ds/m\",\n",
    "            },\n",
    "        },\n",
    "        \"soilList\": output_SoilList_cleaned,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ad57ba-2aca-4e12-98aa-5dc8ff3c64d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using UTM CRS: EPSG:32630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/jmaynard/Documents/GitHub/soil-id-algorithm/soil_id/utils.py:1404: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid = geometry.centroid.iloc[0]\n",
      "/mnt/c/Users/jmaynard/Documents/GitHub/soil-id-algorithm/soil_id/utils.py:84: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  mu_id_dist[\"distance\"] = mu_id_dist.groupby(\"MUGLB_NEW\")[\"dist_meters\"].transform(min)\n",
      "/tmp/ipykernel_256532/971167363.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mucompdata_pd[\"distance\"] = pd.to_numeric(mucompdata_pd[\"distance\"])\n",
      "/tmp/ipykernel_256532/971167363.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mucompdata_pd[\"share\"] = pd.to_numeric(mucompdata_pd[\"share\"])\n",
      "ERROR:root:relation \"landpks_soil_model\" does not exist\n",
      "LINE 2:         INSERT INTO landpks_soil_model\n",
      "                            ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'location': 'global', 'model': 'v2', 'unit_measure': {'distance': 'm', 'depth': 'cm', 'cec': 'cmol(c)/kg', 'clay': '%', 'rock_fragments': 'cm3/100cm3', 'sand': '%', 'ec': 'ds/m'}}, 'soilList': [{'id': {'name': 'Ferric lixisols', 'component': 'Ferric lixisols', 'score_loc': 0.64, 'rank_loc': '1'}, 'site': {'siteData': {'mapunitID': 1453, 'componentID': 107895, 'fao': 'FAO90', 'share': 80, 'distance': 0.0, 'minCompDistance': 0.0, 'soilDepth': 120}, 'siteDescription': {'Description_en': 'Ferric Lixisols form in warm climates with relatively clayey subsoils dominated by kaolinite and iron oxides, but relatively high base saturation. <br> Ferric Lixisols have soft and cemented iron concentrations in subsoils, and poorly developed structure between iron concentrations which can be susceptible to compaction. ', 'Management_en': 'These soils are heavily weathered soils, which means that fertilization (and possibly lime) will be needed for production. <br> Although they do have kaolinite clay and iron oxides, they have fairly low aluminum toxicity. <br> Best production practices for this soil will include regular fertilization, and consistent cropping in perennial crops or forestry. <br> These soils are particularly sensitive to erosion, and so practices that work to maintain surface cover and strong soil structure (such as perennial crops) are needed. ', 'Description_es': 'Los Lixisoles Férricos se forman en climas cálidos con subsuelos relativamente arcillosos dominados por caolinita y óxidos de hierro, pero con una saturación de bases relativamente alta. <br>Los Lixisoles férricos tienen concentraciones de hierro blandas y cementadas en los subsuelos, y una estructura poco desarrollada entre las concentraciones de hierro que puede ser susceptible de compactación. ', 'Management_es': 'Estos suelos están fuertemente meteorizados, lo que significa que la fertilización (y posiblemente la cal) será necesaria para la producción. <br>Aunque tienen arcilla caolinita y óxidos de hierro, tienen una toxicidad de aluminio bastante baja. <br>Las mejores prácticas de producción para este suelo incluirán la fertilización regular, y el cultivo consistente en cultivos perennes o la silvicultura. <br>Los suelos son sensibles a la erosión, por lo que son importantes las prácticas que mantienen la cobertura de la superficie. <br>Estos suelos son especialmente sensibles a la erosión, por lo que se necesitan prácticas que trabajen para mantener una estructura fuerte del suelo (como los cultivos perennes).', 'Description_ks': 'Ferric Lixisols form in warm climates with relatively clayey subsoils dominated by kaolinite and iron oxides, but relatively high base saturation. <br> Ferric Lixisols have soft and cemented iron concentrations in subsoils, and poorly developed structure between iron concentrations which can be susceptible to compaction. ', 'Management_ks': 'These soils are heavily weathered soils, which means that fertilization (and possibly lime) will be needed for production. <br> Although they do have kaolinite clay and iron oxides, they have fairly low aluminum toxicity. <br> Best production practices for this soil will include regular fertilization, and consistent cropping in perennial crops or forestry. <br> These soils are particularly sensitive to erosion, and so practices that work to maintain surface cover and strong soil structure (such as perennial crops) are needed. ', 'Description_fr': 'Ferric Lixisols form in warm climates with relatively clayey subsoils dominated by kaolinite and iron oxides, but relatively high base saturation. <br> Ferric Lixisols have soft and cemented iron concentrations in subsoils, and poorly developed structure between iron concentrations which can be susceptible to compaction. ', 'Management_fr': 'These soils are heavily weathered soils, which means that fertilization (and possibly lime) will be needed for production. <br> Although they do have kaolinite clay and iron oxides, they have fairly low aluminum toxicity. <br> Best production practices for this soil will include regular fertilization, and consistent cropping in perennial crops or forestry. <br> These soils are particularly sensitive to erosion, and so practices that work to maintain surface cover and strong soil structure (such as perennial crops) are needed. '}}, 'bottom_depth': {'sl1': 1, 'sl2': 10, 'sl3': 20, 'sl4': 50, 'sl5': 70, 'sl6': 100, 'sl7': 120}, 'sand': {'sl1': 68.0, 'sl2': 68.0, 'sl3': 68.0, 'sl4': 63.2, 'sl5': 60.43, 'sl6': 57.0, 'sl7': 55.33}, 'clay': {'sl1': 16.0, 'sl2': 16.0, 'sl3': 16.0, 'sl4': 21.6, 'sl5': 24.71, 'sl6': 28.0, 'sl7': 29.33}, 'texture': {'sl1': 'Sandy loam', 'sl2': 'Sandy loam', 'sl3': 'Sandy loam', 'sl4': 'Sandy clay loam', 'sl5': 'Sandy clay loam', 'sl6': 'Sandy clay loam', 'sl7': 'Sandy clay loam'}, 'rock_fragments': {'sl1': 14.0, 'sl2': 14.0, 'sl3': 14.0, 'sl4': 18.6, 'sl5': 19.43, 'sl6': 20.2, 'sl7': 19.83}, 'cec': {'sl1': 8.0, 'sl2': 8.0, 'sl3': 8.0, 'sl4': 7.0, 'sl5': 7.0, 'sl6': 7.0, 'sl7': 7.0}, 'ph': {'sl1': 6.2, 'sl2': 6.2, 'sl3': 6.2, 'sl4': 6.1, 'sl5': 6.03, 'sl6': 5.96, 'sl7': 5.93}, 'ec': {'sl1': 0.0, 'sl2': 0.0, 'sl3': 0.0, 'sl4': 0.0, 'sl5': 0.0, 'sl6': 0.0, 'sl7': 0.0}}, {'id': {'name': 'Plinthic lixisols', 'component': 'Plinthic lixisols', 'score_loc': 0.12, 'rank_loc': '2'}, 'site': {'siteData': {'mapunitID': 1530, 'componentID': 108119, 'fao': 'FAO90', 'share': 60, 'distance': 10697.101, 'minCompDistance': 10697.1012, 'soilDepth': 120}, 'siteDescription': {'Description_en': 'Plinthic Lixisols form in warm climates with relatively clayey subsoils dominated by kaolinite and iron oxides, but relatively high base saturation. <br> Plinthic Lixisols have iron rich, humus poor concentrations of iron in subsoils that irreversibly harden when exposed at the surface. ', 'Management_en': 'These soils are heavily weathered soils, which means that fertilization (and possibly lime) will be needed for production. <br> Although they do have kaolinite clay and iron oxides, they have fairly low aluminum toxicity. <br> Best production practices for this soil will include regular fertilization, and consistent cropping in perennial crops or forestry. <br> The soils are sensitive to erosion, and so practices that maintain surface cover are important. <br> Agronomic practices that protect the soil surface and avoid erosion, so that the iron rich clay layer is not exposed, are critical. <br> Use of rotations and inclusion of deep-rooted crops is also recommended, to help penetrate the clay layer. ', 'Description_es': 'Los Lixisoles Plínticos se forman en climas cálidos con subsuelos relativamente arcillosos dominados por caolinita y óxidos de hierro, pero con una saturación de bases relativamente alta. <br>Los Lixisoles Plénticos tienen concentraciones de hierro ricas en humus en los subsuelos que se endurecen irreversiblemente cuando se exponen en la superficie. ', 'Management_es': 'Estos suelos están fuertemente meteorizados, lo que significa que la fertilización (y posiblemente la cal) será necesaria para la producción. <br>Aunque tienen arcilla caolinita y óxidos de hierro, tienen una toxicidad de aluminio bastante baja. <br>Las mejores prácticas de producción para este suelo incluirán la fertilización regular, y el cultivo consistente en cultivos perennes o la silvicultura. <br>Los suelos son sensibles a la erosión, por lo que son importantes las prácticas que mantienen la cobertura de la superficie. <br>Las prácticas agronómicas que protegen la superficie del suelo y evitan la erosión, de modo que la capa de arcilla rica en hierro no quede expuesta, son fundamentales. <br>También se recomienda el uso de rotaciones y la inclusión de cultivos de raíces profundas, para ayudar a penetrar en la capa de arcilla.', 'Description_ks': 'Plinthic Lixisols form in warm climates with relatively clayey subsoils dominated by kaolinite and iron oxides, but relatively high base saturation. <br> Plinthic Lixisols have iron rich, humus poor concentrations of iron in subsoils that irreversibly harden when exposed at the surface. ', 'Management_ks': 'These soils are heavily weathered soils, which means that fertilization (and possibly lime) will be needed for production. <br> Although they do have kaolinite clay and iron oxides, they have fairly low aluminum toxicity. <br> Best production practices for this soil will include regular fertilization, and consistent cropping in perennial crops or forestry. <br> The soils are sensitive to erosion, and so practices that maintain surface cover are important. <br> Agronomic practices that protect the soil surface and avoid erosion, so that the iron rich clay layer is not exposed, are critical. <br> Use of rotations and inclusion of deep-rooted crops is also recommended, to help penetrate the clay layer. ', 'Description_fr': 'Plinthic Lixisols form in warm climates with relatively clayey subsoils dominated by kaolinite and iron oxides, but relatively high base saturation. <br> Plinthic Lixisols have iron rich, humus poor concentrations of iron in subsoils that irreversibly harden when exposed at the surface. ', 'Management_fr': 'These soils are heavily weathered soils, which means that fertilization (and possibly lime) will be needed for production. <br> Although they do have kaolinite clay and iron oxides, they have fairly low aluminum toxicity. <br> Best production practices for this soil will include regular fertilization, and consistent cropping in perennial crops or forestry. <br> The soils are sensitive to erosion, and so practices that maintain surface cover are important. <br> Agronomic practices that protect the soil surface and avoid erosion, so that the iron rich clay layer is not exposed, are critical. <br> Use of rotations and inclusion of deep-rooted crops is also recommended, to help penetrate the clay layer. '}}, 'bottom_depth': {'sl1': 1, 'sl2': 10, 'sl3': 20, 'sl4': 50, 'sl5': 70, 'sl6': 100, 'sl7': 120}, 'sand': {'sl1': 64.0, 'sl2': 64.0, 'sl3': 64.0, 'sl4': 60.4, 'sl5': 58.29, 'sl6': 56.0, 'sl7': 54.83}, 'clay': {'sl1': 14.0, 'sl2': 14.0, 'sl3': 14.0, 'sl4': 18.4, 'sl5': 20.86, 'sl6': 23.0, 'sl7': 23.83}, 'texture': {'sl1': 'Sandy loam', 'sl2': 'Sandy loam', 'sl3': 'Sandy loam', 'sl4': 'Sandy loam', 'sl5': 'Sandy clay loam', 'sl6': 'Sandy clay loam', 'sl7': 'Sandy clay loam'}, 'rock_fragments': {'sl1': 9.0, 'sl2': 9.0, 'sl3': 9.0, 'sl4': 25.4, 'sl5': 33.29, 'sl6': 36.8, 'sl7': 35.67}, 'cec': {'sl1': 5.0, 'sl2': 5.0, 'sl3': 5.0, 'sl4': 4.6, 'sl5': 4.86, 'sl6': 5.2, 'sl7': 5.33}, 'ph': {'sl1': 6.2, 'sl2': 6.2, 'sl3': 6.2, 'sl4': 6.0, 'sl5': 5.94, 'sl6': 5.9, 'sl7': 5.88}, 'ec': {'sl1': 0.0, 'sl2': 0.0, 'sl3': 0.0, 'sl4': 0.0, 'sl5': 0.0, 'sl6': 0.0, 'sl7': 0.0}}, {'id': {'name': 'Lithic leptosols', 'component': 'Lithic leptosols', 'score_loc': 0.08, 'rank_loc': '3'}, 'site': {'siteData': {'mapunitID': 1453, 'componentID': 107896, 'fao': 'FAO90', 'share': 10, 'distance': 0.0, 'minCompDistance': 0.0, 'soilDepth': 20}, 'siteDescription': {'Description_en': 'Lithic Leptosols have very limited rooting volume due to continuous rock, highly calcareous material, cemented horizons, or many rocks and coarse fragments in the upper portion of the soil. <br> Leptosols on steep slopes are highly erodible. <br> Lithic Leptosols have hard rock within 10 cm of the soil surface. ', 'Management_en': 'Because these soils are shallow, rocky and erodible they should be used for perennial crops, and not tilled. <br> Practices to maintain organic matter and cover should be used. <br> Only uses for grazing or agroforestry should be considered. <br> Preservation of the surface soil with its organic matter is important, and erosion prevention is critical. <br> Land management practices should maximize soil cover. <br> Any agricultural use should be for grazing, with cover continuously maintained. ', 'Description_es': 'Los leptosoles Líticos tienen un volumen de enraizamiento muy limitado debido a la presencia de roca continua, material altamente calcáreo, horizontes cementados o muchas rocas y fragmentos gruesos en la parte superior del suelo. <br>Los leptosoles en pendientes pronunciadas son muy erosionables. <br>Los leptosoles líticos tienen rocas duras a menos de 10 cm de la superficie del suelo. ', 'Management_es': 'Debido a que estos suelos son poco profundos, rocosos y erosionables, deben utilizarse para cultivos perennes, y no deben ser labrados. <br>Deben utilizarse prácticas para mantener la materia orgánica y la cobertura. <br>Sólo deben considerarse los usos para pastoreo o agroforestales. <br>La preservación del suelo superficial con su materia orgánica es importante, y la prevención de la erosión es fundamental. <br>Las prácticas de gestión de la tierra deben maximizar la cobertura del suelo. <br>Cualquier uso agrícola debe ser para el pastoreo, con el mantenimiento continuo de la cobertura.', 'Description_ks': 'Lithic Leptosols have very limited rooting volume due to continuous rock, highly calcareous material, cemented horizons, or many rocks and coarse fragments in the upper portion of the soil. <br> Leptosols on steep slopes are highly erodible. <br> Lithic Leptosols have hard rock within 10 cm of the soil surface. ', 'Management_ks': 'Because these soils are shallow, rocky and erodible they should be used for perennial crops, and not tilled. <br> Practices to maintain organic matter and cover should be used. <br> Only uses for grazing or agroforestry should be considered. <br> Preservation of the surface soil with its organic matter is important, and erosion prevention is critical. <br> Land management practices should maximize soil cover. <br> Any agricultural use should be for grazing, with cover continuously maintained. ', 'Description_fr': 'Lithic Leptosols have very limited rooting volume due to continuous rock, highly calcareous material, cemented horizons, or many rocks and coarse fragments in the upper portion of the soil. <br> Leptosols on steep slopes are highly erodible. <br> Lithic Leptosols have hard rock within 10 cm of the soil surface. ', 'Management_fr': 'Because these soils are shallow, rocky and erodible they should be used for perennial crops, and not tilled. <br> Practices to maintain organic matter and cover should be used. <br> Only uses for grazing or agroforestry should be considered. <br> Preservation of the surface soil with its organic matter is important, and erosion prevention is critical. <br> Land management practices should maximize soil cover. <br> Any agricultural use should be for grazing, with cover continuously maintained. '}}, 'bottom_depth': {'sl1': 1, 'sl2': 10, 'sl3': 20}, 'sand': {'sl1': 51.0, 'sl2': 51.0, 'sl3': 51.0}, 'clay': {'sl1': 20.0, 'sl2': 20.0, 'sl3': 20.0}, 'texture': {'sl1': 'Loam', 'sl2': 'Loam', 'sl3': 'Loam'}, 'rock_fragments': {'sl1': 36.0, 'sl2': 36.0, 'sl3': 36.0}, 'cec': {'sl1': 16.0, 'sl2': 16.0, 'sl3': 16.0}, 'ph': {'sl1': 6.7, 'sl2': 6.7, 'sl3': 6.7}, 'ec': {'sl1': 1.0, 'sl2': 1.0, 'sl3': 1.0}}, {'id': {'name': 'Eutric cambisols', 'component': 'Eutric cambisols', 'score_loc': 0.08, 'rank_loc': '4'}, 'site': {'siteData': {'mapunitID': 1453, 'componentID': 107897, 'fao': 'FAO90', 'share': 10, 'distance': 0.0, 'minCompDistance': 0.0, 'soilDepth': 120}, 'siteDescription': {'Description_en': 'Eutric Cambisols are widely occurring soils with limited soil development. <br> These are productive soils with high base saturation (Ca, Mg and K) in the upper portion of soil. ', 'Management_en': 'In temperate regions the soils will have a high content of basic cations (potassium, calcium and magnesium), while in more humid regions they may have lower levels of soil nutrients. <br> Eutric Cambisols will have high base saturation, which means that the available soil nutrients will be predominantly calcium, potassium, and magnesium. <br> These soils are well suited for crop production, and can be intensively used. <br> Fertilization should be used to improve productivity, and irrigation can be included to further boost productivity. ', 'Description_es': 'Los Cambisoles Eútricos son suelos que se dan ampliamente con un desarrollo limitado del suelo. <br>Son suelos productivos con alta saturación de bases (Ca, Mg y K) en la parte superior del suelo. ', 'Management_es': 'En regiones templadas los suelos tendrán un alto contenido de cationes básicos (potasio, calcio y magnesio), mientras que en regiones más húmedas pueden tener niveles más bajos de nutrientes en el suelo. <br>Los Cambisoles eútricos tendrán una alta saturación de bases, lo que significa que los nutrientes disponibles en el suelo serán predominantemente calcio, potasio y magnesio. <br>Estos suelos son muy adecuados para la producción de cultivos y pueden utilizarse de forma intensiva. <br>La fertilización debe utilizarse para mejorar la productividad, y puede incluirse el riego para aumentar aún más la productividad.', 'Description_ks': 'Eutric Cambisols are widely occurring soils with limited soil development. <br> These are productive soils with high base saturation (Ca, Mg and K) in the upper portion of soil. ', 'Management_ks': 'In temperate regions the soils will have a high content of basic cations (potassium, calcium and magnesium), while in more humid regions they may have lower levels of soil nutrients. <br> Eutric Cambisols will have high base saturation, which means that the available soil nutrients will be predominantly calcium, potassium, and magnesium. <br> These soils are well suited for crop production, and can be intensively used. <br> Fertilization should be used to improve productivity, and irrigation can be included to further boost productivity. ', 'Description_fr': 'Eutric Cambisols are widely occurring soils with limited soil development. <br> These are productive soils with high base saturation (Ca, Mg and K) in the upper portion of soil. ', 'Management_fr': 'In temperate regions the soils will have a high content of basic cations (potassium, calcium and magnesium), while in more humid regions they may have lower levels of soil nutrients. <br> Eutric Cambisols will have high base saturation, which means that the available soil nutrients will be predominantly calcium, potassium, and magnesium. <br> These soils are well suited for crop production, and can be intensively used. <br> Fertilization should be used to improve productivity, and irrigation can be included to further boost productivity. '}}, 'bottom_depth': {'sl1': 1, 'sl2': 10, 'sl3': 20, 'sl4': 50, 'sl5': 70, 'sl6': 100, 'sl7': 120}, 'sand': {'sl1': 40.0, 'sl2': 40.0, 'sl3': 40.0, 'sl4': 39.2, 'sl5': 39.14, 'sl6': 39.6, 'sl7': 39.33}, 'clay': {'sl1': 29.0, 'sl2': 29.0, 'sl3': 29.0, 'sl4': 31.0, 'sl5': 31.43, 'sl6': 31.4, 'sl7': 31.33}, 'texture': {'sl1': 'Clay loam', 'sl2': 'Clay loam', 'sl3': 'Clay loam', 'sl4': 'Clay loam', 'sl5': 'Clay loam', 'sl6': 'Clay loam', 'sl7': 'Clay loam'}, 'rock_fragments': {'sl1': 11.0, 'sl2': 11.0, 'sl3': 11.0, 'sl4': 15.8, 'sl5': 16.57, 'sl6': 17.8, 'sl7': 16.0}, 'cec': {'sl1': 22.0, 'sl2': 22.0, 'sl3': 22.0, 'sl4': 21.6, 'sl5': 21.86, 'sl6': 22.2, 'sl7': 22.67}, 'ph': {'sl1': 6.4, 'sl2': 6.4, 'sl3': 6.4, 'sl4': 6.42, 'sl5': 6.47, 'sl6': 6.58, 'sl7': 6.65}, 'ec': {'sl1': 2.0, 'sl2': 2.0, 'sl3': 2.0, 'sl4': 1.4, 'sl5': 1.29, 'sl6': 1.2, 'sl7': 1.17}}, {'id': {'name': 'Gleyic luvisols', 'component': 'Gleyic luvisols', 'score_loc': 0.06, 'rank_loc': '5'}, 'site': {'siteData': {'mapunitID': 1530, 'componentID': 108120, 'fao': 'FAO90', 'share': 30, 'distance': 10697.101, 'minCompDistance': 10697.1012, 'soilDepth': 120}, 'siteDescription': {'Description_en': 'Gleyic Luvisols are productive soils with high base saturation and relatively clayey subsoils. <br> Gleyic Luvisols are saturated with shallow groundwater in the upper one meter of the soil profile.', 'Management_en': 'These soils are fertile, and can be used for a wide range of cropping practices. <br> However, they are sensitive to soil loss through erosion, and care must be taken to protect the soil from loss. <br> If the soil is already eroded they may best be suited for grazing andtree crops. <br> Drainage of these soils may be needed. <br> However, since this is saturation via groundwater this may not be possible, and thus shallow-rooted crops must be considered. <br> If fertilized and not drained, loss of applied nitrogen (N) by denitrification or leaching is possible. <br> More efficient crop N use in these soils can be achieved by:  1) drainage, and, 2) use of slow-release N fertilizers (if available). ', 'Description_es': 'Los Luvisoles Gleyicos son suelos productivos con alta saturación de la base y subsuelos relativamente arcillosos. <br>Los Luvisoles Gleyicos están saturados con agua subterránea poco profunda en el metro superior del perfil del suelo.', 'Management_es': 'Estos suelos son fértiles y pueden utilizarse para una amplia gama de prácticas de cultivo. <br>Sin embargo, son sensibles a la pérdida de suelo por erosión, y hay que tener cuidado para proteger el suelo de la pérdida. <br>Si el suelo ya está erosionado, pueden ser más adecuados para el pastoreo y/o los cultivos arbóreos. <br>Puede ser necesario el drenaje de estos suelos. <br>Sin embargo, al tratarse de una saturación a través de las aguas subterráneas, esto puede no ser posible, por lo que deben considerarse los cultivos de raíz superficial. <br>Si se fertiliza y no se drena, es posible la pérdida de nitrógeno (N) aplicado por desnitrificación o lixiviación. <br>El uso más eficiente del N por parte de los cultivos en estos suelos puede lograrse mediante:  1) el drenaje, y, 2) el uso de fertilizantes de N de liberación lenta (si están disponibles).', 'Description_ks': 'Gleyic Luvisols are productive soils with high base saturation and relatively clayey subsoils. <br> Gleyic Luvisols are saturated with shallow groundwater in the upper one meter of the soil profile.', 'Management_ks': 'These soils are fertile, and can be used for a wide range of cropping practices. <br> However, they are sensitive to soil loss through erosion, and care must be taken to protect the soil from loss. <br> If the soil is already eroded they may best be suited for grazing andtree crops. <br> Drainage of these soils may be needed. <br> However, since this is saturation via groundwater this may not be possible, and thus shallow-rooted crops must be considered. <br> If fertilized and not drained, loss of applied nitrogen (N) by denitrification or leaching is possible. <br> More efficient crop N use in these soils can be achieved by:  1) drainage, and, 2) use of slow-release N fertilizers (if available). ', 'Description_fr': 'Gleyic Luvisols are productive soils with high base saturation and relatively clayey subsoils. <br> Gleyic Luvisols are saturated with shallow groundwater in the upper one meter of the soil profile.', 'Management_fr': 'These soils are fertile, and can be used for a wide range of cropping practices. <br> However, they are sensitive to soil loss through erosion, and care must be taken to protect the soil from loss. <br> If the soil is already eroded they may best be suited for grazing andtree crops. <br> Drainage of these soils may be needed. <br> However, since this is saturation via groundwater this may not be possible, and thus shallow-rooted crops must be considered. <br> If fertilized and not drained, loss of applied nitrogen (N) by denitrification or leaching is possible. <br> More efficient crop N use in these soils can be achieved by:  1) drainage, and, 2) use of slow-release N fertilizers (if available). '}}, 'bottom_depth': {'sl1': 1, 'sl2': 10, 'sl3': 20, 'sl4': 50, 'sl5': 70, 'sl6': 100, 'sl7': 120}, 'sand': {'sl1': 62.0, 'sl2': 62.0, 'sl3': 62.0, 'sl4': 57.4, 'sl5': 54.57, 'sl6': 51.4, 'sl7': 49.83}, 'clay': {'sl1': 16.0, 'sl2': 16.0, 'sl3': 16.0, 'sl4': 22.2, 'sl5': 25.57, 'sl6': 28.6, 'sl7': 29.83}, 'texture': {'sl1': 'Sandy loam', 'sl2': 'Sandy loam', 'sl3': 'Sandy loam', 'sl4': 'Sandy clay loam', 'sl5': 'Sandy clay loam', 'sl6': 'Sandy clay loam', 'sl7': 'Sandy clay loam'}, 'rock_fragments': {'sl1': 2.0, 'sl2': 2.0, 'sl3': 2.0, 'sl4': 8.4, 'sl5': 13.14, 'sl6': 17.8, 'sl7': 15.67}, 'cec': {'sl1': 9.0, 'sl2': 9.0, 'sl3': 9.0, 'sl4': 10.8, 'sl5': 11.86, 'sl6': 13.0, 'sl7': 13.5}, 'ph': {'sl1': 6.3, 'sl2': 6.3, 'sl3': 6.3, 'sl4': 6.34, 'sl5': 6.41, 'sl6': 6.54, 'sl7': 6.62}, 'ec': {'sl1': 1.0, 'sl2': 1.0, 'sl3': 1.0, 'sl4': 1.0, 'sl5': 1.14, 'sl6': 1.4, 'sl7': 1.67}}]}\n"
     ]
    }
   ],
   "source": [
    "global_return = getSoilLocationBasedGlobal(lon = -1.57, lat=8.95, plot_id=1)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(global_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3ed88-099b-476b-bc70-bfe9e90d1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_return)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
